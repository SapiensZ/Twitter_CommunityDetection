{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter API credentials\n",
    "consumer_key = \"BmvoUUcOUXhPxRR8uRC2TgKoW\"\n",
    "consumer_secret = \"bNV6inRgeUSSVerytnnnTPveW8iM9GM0dwryZyiUKmYy436D1I\"\n",
    "access_key = \"2969993776-b9Ui7fVJjW7gYId2C0kSGo5mN4ki93HSGEn6jx0\"\n",
    "access_secret = \"N5ER33zjeIqfl5918MWTHLWbZzuBGfGL0FeSfNGvSsrvZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OAUTH_KEYS = {'consumer_key':consumer_key, 'consumer_secret':consumer_secret, 'access_token_key':access_key, 'access_token_secret':access_secret}\n",
    "auth = tweepy.OAuthHandler(OAUTH_KEYS['consumer_key'], OAUTH_KEYS['consumer_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of tweets scraped for the time window \n",
    "#(None: all, in theory, but when I tried, the limit is still 10000 ...)\n",
    "n_items_default = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_retweeted(text):\n",
    "    return text[:2] == 'RT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_retweeted(tweet):\n",
    "    try:\n",
    "        RT_info = tweet.split(':')[0]\n",
    "        if '@' in RT_info:\n",
    "            user_RT = RT_info.split()[-1]\n",
    "            user_RT = user_RT.replace('@','')\n",
    "            return user_RT\n",
    "        else:\n",
    "            return False\n",
    "        pass\n",
    "    except IndexError as ve:\n",
    "        print(tweet)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(since_date, until_date, jour, n_items=10000):\n",
    "    if n_items is None:\n",
    "        print('No limit')\n",
    "        cursor = tweepy.Cursor(api.search, q='#confinementjour'+str(jour),\n",
    "                               geocode=\"48.85717,2.34293,10km\",\n",
    "                               since=since_date,\n",
    "                               until=until_date).items()\n",
    "    else:\n",
    "        print('Limit: ', n_items)\n",
    "        cursor = tweepy.Cursor(api.search, q='#confinementjour'+str(jour),\n",
    "                               geocode=\"48.85717,2.34293,10km\",\n",
    "                               since=since_date,\n",
    "                               until=until_date).items(n_items)\n",
    "    tweet_list = []\n",
    "    while True:\n",
    "        try:\n",
    "            tweet = cursor.next()\n",
    "            tweet_list.append(tweet)\n",
    "        except tweepy.TweepError:\n",
    "            time.sleep(60 * 15)\n",
    "            continue\n",
    "        except StopIteration:\n",
    "            break\n",
    "    print('Number of tweets scrapped: ', len(tweet_list))\n",
    "\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_to_df(tweet_list):\n",
    "    \n",
    "    usernames = []\n",
    "    text = []\n",
    "    timestamp = []\n",
    "    count_rt = []\n",
    "    for tweet in tweet_list:\n",
    "        timestamp.append(tweet.created_at)\n",
    "        usernames.append(tweet.user.screen_name)\n",
    "        text.append(tweet.text)\n",
    "        count_rt.append(tweet.retweet_count)\n",
    "        \n",
    "    df = pd.DataFrame()\n",
    "    df['timestamp'] = pd.to_datetime(timestamp)\n",
    "    max_date = max(df.timestamp)\n",
    "    min_date = min(df.timestamp)\n",
    "    df['username'] = usernames\n",
    "    df['count_rt'] = count_rt\n",
    "    df['text'] = text\n",
    "    df['is_retweeted'] = df.text.apply(is_retweeted)\n",
    "    df['user_retweeted'] = df.text.apply(user_retweeted)\n",
    "    print('Finished from ', min_date, ' to ', max_date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = ['2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31',\n",
    "        '2020-04-01', '2020-04-02', '2020-04-03']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With only 10 000 items per time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dates=dates, n_items=n_items_default):\n",
    "    print('Dates that will generates windows ')\n",
    "    print(dates)\n",
    "    print(n_items_default)\n",
    "    for i in range(len(dates) - 1):\n",
    "        print()\n",
    "        t1 = time.time()\n",
    "        tweet_list = scraping(dates[i], dates[i+1],i+11, n_items=n_items_default)\n",
    "        df = scrap_to_df(tweet_list)\n",
    "        csv_name = 'data_day_'+str(i+11)+'_'+ str(dates[i]) + '_' + str(dates[i+1]) + '.csv'\n",
    "        t2 = time.time()\n",
    "        delta_t = t2-t1\n",
    "        print('Time taken (sec):', delta_t)\n",
    "        print('Name of saved csv file: ', csv_name)\n",
    "        print('Shape of the dataframe: ', df.shape)\n",
    "        df.to_csv(csv_name,index = False, encoding='utf-8')\n",
    "        print()\n",
    "    return 'finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates that will generates windows \n",
      "['2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02', '2020-04-03']\n",
      "None\n",
      "\n",
      "No limit\n",
      "Number of tweets scrapped:  97\n",
      "Finished from  2020-03-27 23:12:30  to  2020-03-27 23:59:20\n",
      "Time taken (sec): 10.660658597946167\n",
      "Name of saved csv file:  data_day_11_2020-03-27_2020-03-28.csv\n",
      "Shape of the dataframe:  (97, 6)\n",
      "\n",
      "\n",
      "No limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets scrapped:  7857\n",
      "Finished from  2020-03-28 00:00:58  to  2020-03-28 23:58:10\n",
      "Time taken (sec): 955.1474788188934\n",
      "Name of saved csv file:  data_day_12_2020-03-28_2020-03-29.csv\n",
      "Shape of the dataframe:  (7857, 6)\n",
      "\n",
      "\n",
      "No limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets scrapped:  4822\n",
      "Finished from  2020-03-29 00:07:49  to  2020-03-29 23:59:49\n",
      "Time taken (sec): 870.959575176239\n",
      "Name of saved csv file:  data_day_13_2020-03-29_2020-03-30.csv\n",
      "Shape of the dataframe:  (4822, 6)\n",
      "\n",
      "\n",
      "No limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets scrapped:  6983\n",
      "Finished from  2020-03-30 00:10:11  to  2020-03-30 23:57:11\n",
      "Time taken (sec): 924.154946565628\n",
      "Name of saved csv file:  data_day_14_2020-03-30_2020-03-31.csv\n",
      "Shape of the dataframe:  (6983, 6)\n",
      "\n",
      "\n",
      "No limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets scrapped:  5524\n",
      "Finished from  2020-03-31 00:00:25  to  2020-03-31 23:58:54\n",
      "Time taken (sec): 863.7558588981628\n",
      "Name of saved csv file:  data_day_15_2020-03-31_2020-04-01.csv\n",
      "Shape of the dataframe:  (5524, 6)\n",
      "\n",
      "\n",
      "No limit\n",
      "Number of tweets scrapped:  220\n",
      "Finished from  2020-04-01 21:50:40  to  2020-04-01 23:58:22\n",
      "Time taken (sec): 21.273732662200928\n",
      "Name of saved csv file:  data_day_16_2020-04-01_2020-04-02.csv\n",
      "Shape of the dataframe:  (220, 6)\n",
      "\n",
      "\n",
      "No limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets scrapped:  6191\n",
      "Finished from  2020-04-02 00:35:02  to  2020-04-02 23:59:25\n",
      "Time taken (sec): 892.2771043777466\n",
      "Name of saved csv file:  data_day_17_2020-04-02_2020-04-03.csv\n",
      "Shape of the dataframe:  (6191, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
